<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Projects Overview | Stuart Synakowski</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body class="bg-white text-gray-800 font-sans">
  <!-- Header -->
  <header class="p-6 bg-gray-100 shadow-md">
    <div class="max-w-6xl mx-auto flex flex-col md:flex-row justify-between items-center">
      <h1 class="text-3xl font-bold"><a href="index.html">Stuart Synakowski</a></h1>
      <nav class="mt-2 md:mt-0">
        <a href="index.html#about" class="mx-2">About</a>
        <a href="#" class="mx-2 font-bold text-blue-600">Projects</a>
        <a href="index.html#resume" class="mx-2">Resume</a>
        <a href="index.html#contact" class="mx-2">Contact</a>
        <a href="index.html#random" class="mx-2">Random</a>
      </nav>
    </div>
  </header>

  <div class="max-w-4xl mx-auto p-6">
    <main class="space-y-12">
      <!-- Projects Section -->
      <section id="Projects">
        <h2 class="text-3xl font-bold mb-6 border-b pb-2">Projects Overview</h2>
        <p class="mb-3 text-gray-700">
          I’ve had the chance to work on a pretty wide range of projects that sit at the intersection of research and real-world impact. Most of my work lives in applied AI, machine learning, and computer vision, but some of my AI research pull-ideas from cognitive science and topological data analysis. I also had the chance to work on some computational biophysics projects when I was younger.
        </p>

        <p class="mb-3 text-gray-700">
          What you’ll find below is a high-level snapshot of the kinds of things I’ve been working on. Each project links out to more detail where I can share it. This page is very much a work in progress — I’m always adding, refining, and occasionally re-thinking how I explain things.
        </p>

        <!-- Corporate R&D Projects -->
        <div class="mb-10">
          <h3 class="text-xl font-bold mb-2 text-gray-800 border-b pb-2">Corporate R&D</h3>
          <p class="mb-3 text-gray-700">
            At P&G, my role has mostly been about exploring what’s new in AI and figuring out where it can actually create value for real business problems. Most of those problems live in accelerating clinical and consumer research.
          </p>

          <p class="mb-3 text-gray-700">
            In practice, that usually means building AI tools that help researchers move faster, scale their work, or see patterns they couldn’t easily see before. My typical workflow starts with deeply understanding how my collaborators already work — their processes, bottlenecks, and constraints — and then experimenting with AI techniques that might meaningfully improve those workflows.
          </p>

          <p class="mb-3 text-gray-700">
            I can’t share many of the details, but I try to give high-level overviews of the underlying ideas and approaches. The goal here isn’t to show off products, but to explain the concepts, trade-offs, and ways of thinking that drive the work.
          </p>



          <div class="ml-4 mb-8">
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-blue-500 pl-2">GenAI tools Tailored for Value Creation in Clinical and Consumer Research</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              <div class="mb-4">
                  <img src="images/genAI_research_cover_photo_v3.png" 
                      alt="Overview of GenAI Tools and Workflows" 
                      class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
                </div>
            
            
            
              
              <!-- Text Content -->
              <div>
                <p class="mb-3 text-gray-700">
                  Large language models clearly accelerate research, but the path from utility to measurable value creation is still unclear. Tools like chatbots and vanilla RAG systems help with report generation and knowledge lookup, yet they are not well integrated into the real workflows clinicial scientists and product researchers use to drive impact.
                </p>

                <p class="mb-3 text-gray-700">
                  I’ve found that measurable value emerges when domain experts can orchestrate LLMs directly within their existing processes. Much of my work focuses on building tools that democratize this orchestration—making advanced LLM capabilities accessible, reliable, and easy to use for non-technical experts.
                </p>


                <p class="mb-3 text-gray-700">
                  In practice, this has enabled users to automate tedious text-processing tasks, mine and analyze massive datasets, extract and structure relevant information, and generate hypotheses at scale. These tools have proven especially effective for analyzing large volumes of consumer transcripts to surface patterns in customer sentiment and prioritize product improvements. They have also helped structure and consolidate decades of internal clinical research to support claims or develope/identify new research directions.
                </p>

                <h2 class="text-xl font-bold mb-3 text-gray-800">Key Themes</h2>
                  <p class="mb-3 text-gray-700">
                    Democratizing LLM orchestration, building insight co-pilots for large-scale analysis, automated hypothesis generation, and ensuring reproducibility and interpretability in LLM outputs.
                  </p>
                </h2>

                <a href="corporate_RandD/GenAI_tools.html" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  Read more about the concepts behind these GenAI tools
                  <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>
              </div>

            </div>
          </div>


          <!-- Skin AI -->
          <div class="ml-4 mb-8">
            
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-blue-500 pl-2">AI & Computer Vision for Skin Analysis</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              
              <!-- Image as Cover Photo (Full Width) -->
              <div class="mb-4">
                <img src="images/SKIN_AI_cover_photo_v2.png" 
                     alt="AI for Skin Analysis Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>
              
              <!-- Text Content -->
              <div>
                <p class="mb-3 text-gray-700">
                  A lot of my work at P&G focuses on building computer vision and machine learning tools to better understand skin. I’ve developed a suite of methods for synthetic skin image generation to support perception studies, high-quality image capture for clinical research, appearance metrics for tracking treatment progress, and models that predict treatment response from selfies.
                </p>

                <p class="text-gray-700">
                The work is deeply interdisciplinary. I collaborate closely with clinical and biomolecular scientists, product and consumer researchers, and statisticians to turn messy, real-world questions about skin into measurable, scalable insights.
                </p>

                  <p class="text-gray-700 italic">
                      I’ve been working in this space long enough that I could probably teach a course or write a book on it. If any of this sounds interesting, check out the links below for higher-level explanations of the core ideas.
                  </p>


                <h2 class="text-xl font-bold mb-3 text-gray-800">Key Themes</h2>
                  <p class="mb-3 text-gray-700">
                     Synthetic skin generation, perceptual modeling, skin appearance metrics, mobile image quality and calibration, optics and color science, first-principles computer vision, and predictive modeling for treatment response — with a healthy dose of cognitive science mixed in.
                  </p>
                </h2>

                <a href="corporate_RandD/AI_for_skin.html" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  Read more about these projects
                  <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>


              </div>

            </div>
          </div>


          <!-- Computer Vision for Consumer Research -->
          <div class="ml-4 mb-8">
            
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-blue-500 pl-2">AI systems for Consumer Research</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              
              <!-- Image as Cover Photo (Full Width) -->
              <div class="mb-4">
                <img src="images/computervision_CR_cover_photo_v0.png" 
                     alt="AI for Skin Analysis Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>
              
              <!-- Text Content -->
              <div>
                <p class="mb-3 text-gray-700">
                 Earlier at P&G, I worked on applying more classical computer vision techniques to consumer research problems. A common challenge for product teams is understanding how people actually interact with products at a fine-grained level. To support this, I built tools that spatially track products and users to infer micro-actions during real product use.
                </p>

                <p class="mb-3 text-gray-700">
                 I also worked on problems around product fit. Many consumer products physically interact with the body, so getting the geometry right matters. I developed photogrammetry-based methods to estimate specific regions of the human body and assess how well products fit real consumers.
                </p>

                <p class="mb-3 text-gray-700">
                 A lot of this work took advantage of the sensing hardware built into iPhone Pro devices — including depth, camera, and motion capabilities — to bring more quantitative measurement into everyday consumer research.
                </p>


                <h2 class="text-xl font-bold mb-3 text-gray-800">Key Themes</h2>
                  <p class="mb-3 text-gray-700">
                     First-principles computer vision and image processing, 3D modeling, action analysis, object detection, and human pose estimation.
                  </p>
                </h2>

                <a href="corporate_RandD/AI_for_skin.html" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  Read more about these projects
                  <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>
              </div>

            </div>
          </div>


          <!-- Sustainability Research -->
          <div class="ml-4 mb-8">
            
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-blue-500 pl-2">AI Consulting for Sustainability Initiatives</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              
              <!-- Image as Cover Photo (Full Width) -->
              <div class="mb-4">
                <img src="images/Perfect_Sort_Consortium.png" 
                     alt="AI for Skin Analysis Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>
              
              <!-- Text Content -->
              <div>

                <p class="mb-3 text-gray-700">
                 One project I’m especially proud of was representing P&G as part of the The Perfect Sort Consortium, a collaboration between industry partners and the National Test Centre for Circular Plastics (NTCP) focused on improving the sortability of plastic packaging waste using AI vision systems.
                </p>

                <p class="mb-3 text-gray-700">
                 For a bit of context: in most developed countries, recyclable waste passes through a Material Recovery Facility (MRF), where automated vision systems play a critical role in identifying and sorting materials that still have economic value. One of the consortium’s core goals was improving plastic sorting — especially separating food-grade from non-food-grade plastics — which is a key bottleneck for building a truly circular plastics economy.
                </p>

                <p class="mb-3 text-gray-700">
                 There are a lot of startups working on vision-based sorting in this space. My role was to help map out a long-term technical solution for AI waste sorting vision systems. I developed an evaluation criteria for companies pitching their solutions to the consortium. I worked closely with plastics scientists, recycling experts, and packaging teams to translate real-world constraints into technical requirements.
                </p>
                <p class="mb-3 text-gray-700">
                  I learned a lot about the technical, economic, and political challenges that still stand in the way of effective recycling. I also walked away with a long list of ideas for how AI could push us closer to a circular economy.
                </p>

                <p class="mb-3 text-gray-700">
                  If you’re working in this space and need technical guidance, feel free to reach out — this is the kind of problem I’d happily spend my life working on.
                </p>

                <h2 class="text-xl font-bold mb-3 text-gray-800">Key Themes</h2>
                  <p class="mb-3 text-gray-700">
                     AI consulting, AI for sustainability, vision-based waste sorting, circular economy, for-profit and non-profit collaborations for environmental impact.
                  </p>
                  

                <a href="https://www.linkedin.com/posts/nationaal-testcentrum-circulaire-plastics_demonstration-day-22-june-2023-of-ai-based-ugcPost-7081558742730698752-aNgL?utm_source=social_share_send&utm_medium=member_desktop_web&rcm=ACoAACLSyysBBBYYkhegSNf_gsiX1H82VjxdxfE" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  see a video from demostration day
                  <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>

                <a href="https://www.linkedin.com/posts/stuart-synakowski_perfect-sorting-consortium-press-release-activity-6917149778870976512-1jva?utm_source=social_share_send&utm_medium=member_desktop_web&rcm=ACoAACLSyysBBBYYkhegSNf_gsiX1H82VjxdxfE" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  short press release 
                  <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>

              </div>

            </div>
          </div>
          


        </div>

        <!-- Research -->
        <div>
          <h3 class="text-xl font-bold mb-6 text-gray-800">AI Research Projects (Graduate Work)</h3>

            <p class="mb-3 text-gray-700">
                The problem definitions in my PhD work were intentionally broad (I had a mild case of scope creep because the ideas were interesting). In hindsight, several of these projects probably could have been split into multiple papers, but as my advisor liked to say, “don’t slice the salami.” Feel free to check out the work below. I still think the ideas hold up and remain relevant to modern AI systems.
            </p>

                <a href="AIresearch/thesis.html" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                  Here is a More detailed Overview of My PhD Thesis
                 <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                </a>


            <h2 class="text-xl font-bold mb-3 text-gray-800">A Recurring Problem in AI: Sharing Knowledge Between Systems</h2>
              <p class="mb-3 text-gray-700">
                    A central theme in my research is how AI systems can share knowledge across tasks. Humans are remarkably efficient at learning new tasks from very little data, while modern AI systems often require massive datasets and compute. Work by François Chollet highlights this gap and motivates the need for representations that allow systems to reuse knowledge acquired from prior tasks. While approaches like transfer learning and meta-learning exist, it’s still unclear what knowledge is being shared and how it is represented inside modern models. My PhD work explored concrete ways to represent and leverage shared knowledge in computer vision systems.
              </p>

            </h2>
          
          <!-- Topology -->
          <div class="ml-4 mb-8">
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-green-500 pl-2">Leveraging the Structure of Deep Neural Networks that Learn</h4>
             <div class="mb-4">
                <img src="images/Topology_Research_Cover_Photo.png" 
                     alt="AI AI for Topology Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>




            
            <div class="space-y-4 pl-4 border-l border-gray-200 ml-1">
              <div class="flex items-start space-x-4">
                
                <div>


                  <p class="mb-3 text-gray-700">
                      One line of work examines the topological structure of deep networks. Certain topological properties of learned representations correlate strongly with generalization performance, independent of model architecture or task. I developed fast, differentiable proxies for these properties, enabling early stopping, task similarity estimation, and topological constraints on learning.
                  
                      <a href="https://arxiv.org/abs/2111.15651" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                         Feel free to check it out on Arxiv
                         <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                      </a>
                  
                  </p>



                </div>
              </div>
            </div>
          </div>
          
          <!-- Intent -->
          <div class="ml-4 mb-8">
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-green-500 pl-2">Computer Vision Research</h4>

            <div class="mb-4">
                <img src="images/Intent_Cover_Photo_v2.png" 
                     alt="AI for Skin Analysis Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>

            <div class="space-y-4 pl-4 border-l border-gray-200 ml-1">
              
              <div class="flex items-start space-x-4">

                <div>
                  A second line of work focuses on intent recognition. Humans readily infer intention even in abstract settings (e.g., simple moving shapes). By identifying first-principles cues like self-propelled motion, I built systems that infer intent in simplified scenes and generalize the same inference rules to motion capture data and real-world video. This work was published in International Journal of Computer Vision.

                        <a href="https://link.springer.com/article/10.1007/s11263-020-01404-0" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                         You should be able to download it for free here
                         <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
                      </a>

                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Physics Projects -->
        <div class="mt-10">
          <h3 class="text-xl font-bold mb-6 text-gray-800">Physics Projects</h3>

          <p class="mb-3 text-gray-700"> Before moving fully into AI and engineering, I originally planned to pursue a PhD in physics. As an undergraduate, I had the chance to work on several computational physics projects that strongly shaped how I think about modeling, first principles, and simulation.
          </p> 

            
            <div class="mb-4">
                <img src="images/Physics_Research_Photo1.png" 
                     alt="AI for Skin Analysis Overview" 
                     class="rounded-lg shadow-md w-full h-auto object-cover border border-gray-100">
              </div>

          <!-- Crystal Structures -->
          <div class="ml-4 mb-8">
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-purple-500 pl-2">Computational Models of Crystal Structures</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              <div class="text-sm text-gray-600 mb-2">NSF Physics REU Lehigh University 2016</div>

            <p class="mb-3 text-gray-700">
              One fascinating idea in materials science is that you can “program” how particles interact by coating them with specific DNA strands. By choosing the DNA sequences, you can effectively design the interaction rules and induce different crystal lattice structures.
            </p>
            <p class="mb-3 text-gray-700">
              I worked on computational models that approximated the pair potentials between DNA-coated particles (loosely inspired by modified Lennard–Jones–potential particle interactions). Using lightweight simulations, we explored how different DNA encodings influenced lattice properties, including sensitivity to temperature and melting behavior.
            </p>
            <p class="mb-3 text-gray-700">
              This project was my first real exposure to large-scale scientific computing — writing Python and bash scripts, running simulations on XSEDE supercomputers, and thinking carefully about how to balance physical fidelity with computational efficiency.I built computational models to simulate how these DNA-coated particles self-assemble into different crystal structures. The simulations helped validate theoretical predictions and provided insights into the dynamics of the assembly process.
            </p>

            </div>
          
            <a href="https://jeetain.wixsite.com/mittal-lab/people" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                Feel free to checkout Jeetain Mittal's research group (Moved to Texas) 
            <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
            </a>
          
          </div>

          <!-- Nanopore Sensors -->
          <div class="ml-4 mb-8">
            <h4 class="text-lg font-semibold mb-3 text-gray-700 border-l-4 border-purple-500 pl-2">Computational Models of Dielectrics in Nanopore Sensors</h4>
            <div class="pl-4 border-l border-gray-200 ml-1">
              <div class="text-sm text-gray-600 mb-2">Physics REU Clarkson University 2015</div>

              <p class="mb-3 text-gray-700"> Nanopores show a lot of promise for applications like particle filtering and DNA sequencing, where information is inferred from changes in ionic current as particles pass through a pore.
              </p>
              <p class="mb-3 text-gray-700">I worked on modeling ionic current flow through cylindrical nanopores partially blocked by dielectric nanoparticles. Using COMSOL Multiphysics (and some Fortran-based simulations), we built finite-element and analytical models to describe how current blockage depends on particle geometry and material properties.
              </p>
              <p class="mb-3 text-gray-700">The goal was to better understand how physical characteristics of particles could be inferred from electrical signals — a theme that, in hindsight, connects pretty directly to many inverse problems I still find interesting today.
              </p>


            </div>

            <a href="https://people.clarkson.edu/~mgrachev/research.html" class="text-blue-600 hover:underline font-medium inline-flex items-center mt-2">
                Feel free to checkout Maria Gracheva's research group
            <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path></svg>
            </a>

          </div>
        </div>
      </section>
    </main>
  </div>

  <!-- Footer -->
  <footer class="p-6 text-center text-gray-500 border-t mt-12">
    © 2025 Stuart Synakowski
  </footer>
</body>
</html>
